---
title: "R Notebook"
output: html_notebook
---

This notebook is just me playing around with some weather data using machine learning

```{r setup}
library(png)
library(reticulate)
use_python("/opt/homebrew/bin/python3")
library(tidyverse)
```

```{r import1}
# first load the data using the API:
# this url loads everything available for station FCL01
df_url <- "https://coagmet.colostate.edu/data/hourly/fcl01.csv?header=yes&from=start&to=end&fields=t,rh,dewpt,vp,solarRad,rso,precip,windSpeed,windDir,windStdDev,gustSpeed,gustTime,gustDir,hourlyETr,hourlyETo,st5cm,st15cm"
df_raw <- read_csv(df_url)

names(df_raw) <- c("station", "date_time", "air_temp_f", "rh_%", "dewpoint_f", "vapor_pressure_kpa", "solar_rad_w_m-2",
                 "rso_w_m-2", "precip_in", "wind_mph", "wind_dir_deg", "wind_std_dev_deg", "gust_speed_mph", "gust_time",
                 "gust_dir_deg", "etr_in_hr-1", "eto_in_hr-1", "soil_temp_5cm_f", "soil_temp_15cm_f")

df_cleaned <- df_raw %>%
  filter(station != "id") %>% # removes header column
  unique() %>%
  select(-station) %>%
  select(-soil_temp_5cm_f, -soil_temp_15cm_f) %>% # soil temp data was introduced fairly late
  pivot_longer(cols=c(-date_time)) %>%
  filter(value != "-999" & value != "NaN") %>%
  mutate(date_time=as.POSIXct(date_time, format="%m/%d/%Y %H:%M")) %>%
  mutate(value=as.numeric(value)) %>%
  na.omit() %>%
  group_by(date_time, name) %>%
  summarize(value=max(value)) %>% # eliminate duplicate values
  pivot_wider(id_cols=c(date_time), names_from="name", values_from="value") %>%
  na.omit() %>%
  pivot_longer(cols=c(-date_time))

df_long <- df_cleaned

saveRDS(df_long, "Weather_ML.rds")

df_long <- readRDS("Weather_ML.rds")

```

``` {r export1}
df_wide <- df_long %>%
  pivot_wider(names_from="name", values_from="value")

write_csv(df_wide, "Weather_ML.csv")

```

```{python import2}
import pandas as pd

df = pd.read_csv("Weather_ML.csv")

# convert date_time to datetime data type
df['date_time'] = pd.to_datetime(df['date_time'])

# set the index as date_time
df = df.set_index('date_time')

# add year, month, and hour as factor variables
df['year'] = df.index.year.astype("object")
df['month'] = df.index.month.astype("object")
df['hour'] = df.index.hour.astype("object")
```

```{python play}
from matplotlib import pyplot as plt
import numpy as np

# now let's play around
df1 = df[["year", "month", "hour", "air_temp_f", "dewpoint_f", "rh_%", "vapor_pressure_kpa", "solar_rad_w_m-2", "wind_mph", "wind_dir_deg", "precip_in", "eto_in_hr-1"]]

# let's see how well we can predict reference crop ET
from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(df1, test_size=0.2, random_state=42)

X_train = train_set.copy()
X_train = train_set.drop("eto_in_hr-1", axis=1)
y_train = train_set["eto_in_hr-1"].copy()

X_test = test_set.copy()
X_test = test_set.drop("eto_in_hr-1", axis=1)
y_test = test_set["eto_in_hr-1"].copy()

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import make_pipeline
num_pipeline = make_pipeline(SimpleImputer(strategy="median"), StandardScaler())
cat_pipeline = make_pipeline(SimpleImputer(strategy="most_frequent"), OneHotEncoder(handle_unknown="ignore"))

from sklearn.compose import make_column_selector, make_column_transformer

preprocessing = make_column_transformer(
  (num_pipeline, make_column_selector(dtype_include=np.number)),
  (cat_pipeline, make_column_selector(dtype_include=object)),
)

from sklearn.ensemble import RandomForestRegressor
forest = make_pipeline(preprocessing, RandomForestRegressor(random_state=42))

feature_names = list(train_set.drop("eto_in_hr-1", axis=1).columns)
forest = RandomForestRegressor(random_state=0)
forest.fit(X_train, y_train)

importances = forest.feature_importances_
std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)

forest_importances = pd.Series(importances, index=feature_names)

print(forest_importances)

y_pred = forest.predict(X_test)

from sklearn import metrics
print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
```

